\newpage\section{Детали реализации}

В настоящем разделе фиксируем ключевые детали реализации Convformer.

\noindent\hspace*{3em}\begin{minipage}{\dimexpr\linewidth-8em}
\begin{algorithm}[H]
\caption{Блок ConvStem}
\label{alg:convstem_pseudocode}
% \small\sffamily % аккуратный шрифт: чуть меньше, без засечек
\begin{spacing}{1.25}
\begin{algorithmic}[1]

\Require входное окно $\mathcal{X}_t \in \mathbb{R}^{B \times L_x \times C_{\text{in}}}$
\Ensure выход $\mathcal{X}'_t \in \mathbb{R}^{B \times L_x \times d_{\text{model}}}$

\Statex

\State $\mathcal{X}_t \gets \mathtt{Permute}(\mathcal{X}_t)$ 
\Comment{$\mathcal{X}_t \in \mathbb{R}^{B \times C_{\text{in}} \times L_x}$}

\State $R \gets \mathtt{Conv1D}_{k=1,p=0}(\mathcal{X}_t)$ 
\Comment{$R \in \mathbb{R}^{B \times d_{\text{model}} \times L_x}$}

\State $H_1 \gets \mathtt{GELU}\,\!\bigl(\mathtt{IN}(\mathtt{Conv1D}_{k=5,p=2}(\mathcal{X}_t))\bigr)$
\Comment{$H_1 \in \mathbb{R}^{B \times d_{\text{model}} \times L_x}$}

\State $H_2 \gets \mathtt{GELU}\,\!\bigl(\mathtt{IN}(\mathtt{DW\text{-}Conv1D}_{k=3,p=1} (H_1))\bigr)$
\Comment{$H_2 \in \mathbb{R}^{B \times d_{\text{model}} \times L_x}$}

\State $Z \gets R + H_2$
\Comment{$Z \in \mathbb{R}^{B \times d_{\text{model}} \times L_x}$}

\State $\mathcal{X}'_t \gets \mathtt{Permute}^{-1}(Z)$
\Comment{$\mathcal{X}'_t \in \mathbb{R}^{B \times L_x \times d_{\text{model}}}$}

\State \Return $\mathcal{X}'_t$

\end{algorithmic}
\end{spacing}
\end{algorithm}
\vspace{-10pt}
\textit{Комментарий.} Здесь $\mathtt{IN}$ обозначает слой InstanceNorm1d~\cite{InstanceNorm} с обучаемыми
параметрами (affine = True), $\mathtt{DW\text{-}Conv1D}$~-- глубинную одномерную
свёртку по временной оси (groups $= d_{\text{model}}$), а $\mathrm{GELU}$ -- функцию активации.
\end{minipage}

\vspace{10pt}

\begin{table}[!ht]
    \centering
    \begin{adjustbox}{max width=\textwidth, max totalheight=\textheight, keepaspectratio}
    \begin{tabular}{l|l|c}
        \toprule
        \multicolumn{2}{l}{\textbf{Encoder:}} & $N$ \\
        \midrule
        Inputs
            & ConvEmbedding $(d_{\mathrm{model}} = 512)$
            &  \\[2pt]
        \cmidrule(lr){1-2}
        \multirow{2}{*}{FAVOR+ } 
            & Multi-head FAVOR$+$ attention ($h=8$, $d_k=64$, $r=256$)
            & \multirow{6}{*}{$2$} \\
         \multirow{2}{*}{self-attention block}  
            & Add, SeriesDecomp ($k=25$), Dropout ($p=0.05$)
            & \\
         \multirow{2}{*}{ \& decomposition}   
            & Pos-wise FFN ($d_{ff}=2048$), RELU
            & \\
            & Add, SeriesDecomp ($k=25$), Dropout ($p=0.05$)
            & \\[2pt]
        \cmidrule(lr){1-2}
        \multirow{2}{*}{Distilling}
            & Conv1d ($k=3, p=2$), BatchNorm1d
            &  \\
            & ELU, MaxPool1d ($k=3, p=1, s=2$)
            & \\
        \midrule
        \multicolumn{2}{l}{\textbf{Decoder:}} & $M$ \\
        \midrule
        Inputs
            & ConvEmbedding $(d_{\mathrm{model}} = 512)$
            & \\[2pt]
        \cmidrule(lr){1-2}
        FAVOR+ self-attention block
            & Multi-head FAVOR+ attention ($h=8, d_k=64, r=256$) + Mask
            & \\[2pt]
        \cmidrule(lr){1-2}
            \multirow{2}{*}{Full Attention} & Multi-head Attention ($h=8, d_k=64$)
            & \multirow{2}{*}{1} \\
            \multirow{2}{*}{cross-attention block}
            & Add, SeriesDecomp ($k=25$), Dropout ($p=0.05$)
            & \\
            \multirow{2}{*}{\& decomposition} 
            & Pos-wise FFN ($d_{ff}=2048$), RELU
            & \\
            & Add, SeriesDecomp ($k=25$), Dropout ($p=0.05$)
            & \\[2pt]
        \midrule
        \multicolumn{2}{l}{\textbf{Final:}} &  \\ 
        \midrule
        Outputs
            & Seasonal part $+$ trend part, Linear $(d_{\mathrm{model}} \rightarrow C_{\mathrm{out}})$
            & \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \vspace{5pt}
    \caption{Гиперпараметры и конфигурация архитектуры предлагаемой модели (Convformer).}
\end{table}
